#!/bin/bash

# dolphinscheduler or airflow or custom
export SCHEDULER="dolphinscheduler"
export SPRING_PROFILES_ACTIVE="hadoop,${SCHEDULER}"

# Scheduler MySQL
export SCHEDULER_MYSQL_ADDRESS="postgres:5432"
export SCHEDULER_MYSQL_DB="postgres"
export SCHEDULER_DATASOURCE_URL="jdbc:postgres://${SCHEDULER_MYSQL_ADDRESS}/${SCHEDULER_MYSQL_DB}"
export SCHEDULER_DATASOURCE_USERNAME="postgres"
export SCHEDULER_DATASOURCE_PASSWORD="postgres"

# Compass MySQL
export COMPASS_MYSQL_ADDRESS="postgres:5432"
export COMPASS_MYSQL_DB="postgres"
export SPRING_DATASOURCE_URL="jdbc:postgres://${COMPASS_MYSQL_ADDRESS}/${COMPASS_MYSQL_DB}"
export SPRING_DATASOURCE_USERNAME="postgres"
export SPRING_DATASOURCE_PASSWORD="postgres"

# Kafka
export SPRING_KAFKA_BOOTSTRAPSERVERS="kafka:9092"

# Redis
export SPRING_REDIS_CLUSTER_NODES="redis:6379"
# Optional
export SPRING_REDIS_PASSWORD=""

# Zookeeper
export SPRING_ZOOKEEPER_NODES="zookeeper:2181"

# OpenSearch (default version: 1.3.12) or Elasticsearch (7.x~)
export SPRING_OPENSEARCH_NODES="elasticsearch:9200"
# Optional
export SPRING_OPENSEARCH_USERNAME=""
# Optional
export SPRING_OPENSEARCH_PASSWORD=""
# Optional, needed by OpenSearch, keep empty if OpenSearch does not use truststore.
export SPRING_OPENSEARCH_TRUSTSTORE=""
# Optional, needed by OpenSearch, keep empty if OpenSearch does not use truststore.
export SPRING_OPENSEARCH_TRUSTSTOREPASSWORD=""

# Prometheus for flink, ignore it if you do not use flink.
# export FLINK_PROMETHEUS_HOST="http://localhost:9090"
# export FLINK_PROMETHEUS_TOKEN=""
# export FLINK_PROMETHEUS_DATABASE=""

# task-canal
export CANAL_INSTANCE_MASTER_ADDRESS=${SCHEDULER_MYSQL_ADDRESS}
export CANAL_INSTANCE_DBUSERNAME=${SCHEDULER_DATASOURCE_USERNAME}
export CANAL_INSTANCE_DBPASSWORD=${SCHEDULER_DATASOURCE_PASSWORD}
if [ ${SCHEDULER} == "dolphinscheduler" ]; then
  export CANAL_INSTANCE_FILTER_REGEX="${SCHEDULER_MYSQL_DB}.t_ds_user,${SCHEDULER_MYSQL_DB}.t_ds_project,${SCHEDULER_MYSQL_DB}.t_ds_task_definition,${SCHEDULER_MYSQL_DB}.t_ds_task_instance,${SCHEDULER_MYSQL_DB}.t_ds_process_definition,${SCHEDULER_MYSQL_DB}.t_ds_process_instance,${SCHEDULER_MYSQL_DB}.t_ds_process_task_relation"
elif [ ${SCHEDULER} == "airflow" ]; then
  export CANAL_INSTANCE_FILTER_REGEX="${SCHEDULER_MYSQL_DB}.dag,${SCHEDULER_MYSQL_DB}.serialized_dag,${SCHEDULER_MYSQL_DB}.ab_user,${SCHEDULER_MYSQL_DB}.dag_run,${SCHEDULER_MYSQL_DB}.task_instance"
else
  export CANAL_INSTANCE_FILTER_REGEX=".*\\..*"
fi

export CANAL_ZKSERVERS=${SPRING_ZOOKEEPER_NODES}
export KAFKA_BOOTSTRAPSERVERS=${SPRING_KAFKA_BOOTSTRAPSERVERS}
export CANAL_MQ_TOPIC="mysqldata"
export CANAL_SERVERMODE="kafka"

# task-canal-adapter
export CANAL_ADAPTER_KAFKA_BOOTSTRAP_SERVERS=${SPRING_KAFKA_BOOTSTRAPSERVERS}
# source mysql
export CANAL_ADAPTER_SOURCE_MYSQL_URL=${SCHEDULER_DATASOURCE_URL}
export CANAL_ADAPTER_SOURCE_MYSQL_USERNAME=${SCHEDULER_DATASOURCE_USERNAME}
export CANAL_ADAPTER_SOURCE_MYSQL_PASSWORD=${SCHEDULER_DATASOURCE_PASSWORD}
# destination mysql
export CANAL_ADAPTER_DESTINATION_MYSQL_URL=${SPRING_DATASOURCE_URL}
export CANAL_ADAPTER_DESTINATION_MYSQL_USERNAME=${SPRING_DATASOURCE_USERNAME}
export CANAL_ADAPTER_DESTINATION_MYSQL_PASSWORD=${SPRING_DATASOURCE_PASSWORD}

# task-syncer
# source mysql
export SPRING_DATASOURCE_DYNAMIC_DATASOURCE_SOURCE_URL=${SCHEDULER_DATASOURCE_URL}
export SPRING_DATASOURCE_DYNAMIC_DATASOURCE_SOURCE_USERNAME=${SCHEDULER_DATASOURCE_USERNAME}
export SPRING_DATASOURCE_DYNAMIC_DATASOURCE_SOURCE_PASSWORD=${SCHEDULER_DATASOURCE_PASSWORD}
# destination mysql
export SPRING_DATASOURCE_DYNAMIC_DATASOURCE_DIAGNOSE_URL=${SPRING_DATASOURCE_URL}
export SPRING_DATASOURCE_DYNAMIC_DATASOURCE_DIAGNOSE_USERNAME=${SPRING_DATASOURCE_USERNAME}
export SPRING_DATASOURCE_DYNAMIC_DATASOURCE_DIAGNOSE_PASSWORD=${SPRING_DATASOURCE_PASSWORD}

