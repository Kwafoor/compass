USER_NOT_EXIST=User does not exist
LOGIN_FAILED=Wrong username or password
TOKEN_VERIFY_FAILED=Login failed, please login again
# FlinkTaskDiagnosisController
OPTIMIZE_MEMORY=The total amount of memory the task can optimize
OPTIMIZE_CORE=The total number of cores that can be optimized by the task
TASK_PARALLEL=Task Parallel
TASK_TM_MEM=TM memory
TASK_TOTAL_MEMORY=Total memory
TASK_SLOT_AMOUNT=Slot amount
TASK_JM_MEMORY=JM memory
TASK_TOTAL_CORE=Total core
TASK_ADVICE_CORE=The total number of cores recommended for the task
TASK_ADVICE_PARALLEL=Task recommendation parallel
TASK_ADVICE_TM_MEM=Task suggestions tm memory
TASK_ADVICE_TOTAL_MEMORY=Recommended total memory for tasks
TASK_ADVICE_JM_MEMORY=Task suggestion jm memory
DESC=desc
ASC=asc
PARALLEL=Parallel
TM_SLOT_AMOUNT=TM slot amount
TM_CORE_AMOUNT=TM core amount
TM_MEM=TM memory MB
JM_MEM=jm memory MB
TM_NUM=tm amount
DIAGNOSIS_START_TIME=Diagnosis start time
DIAGNOSIS_END_TIME=Diagnosis end time
DIAGNOSIS_PARALLEL=Diagnosis parallel
DIAGNOSIS_JM_MEM_SIZE=Diagnosis JM memory size
DIAGNOSIS_TM_SLOT_NUM=Diagnosis TM slot amount
DIAGNOSIS_TM_CORE_NUM=Diagnosis TM core amount
DIAGNOSIS_TM_NUM=Diagnosis TM amount
METRIC_JOB_NAME=Metric job name
FLINK_TRACK_URL=Flink track url
APPLICATION_ID=Application ID
NO_DATA_PERIOD=There is no data in this period
# RunError
LOG_TYPE=Log type
EVENT=Event
LOG_TIME=Log time
LOG_CONTENT=Log content
ADVICE=advice
# BigTableScan
HIVE_TABLE=Scanned hive table name
COLUMNS=Number of scan lines
THRESHOLD=Threshold
# GlobalSort
TASK_NUM=Task amount
DATA_OF_COLUMN=Processing data size
DURATION=duration
# OOMWarn
BROADCAST_HIVE_TABLE=Hive table name
OUTPUT_OF_COLUMNS=Number of output rows after filtering
MEMORY_USED=Memory used size
# FlinkTaskAnalysisInfo
JOB_PARALLEL=Job parallel
JOB_SLOT_AMOUNT=Job slot amount
JOB_TM_CORE_AMOUNT=Job tm slot amount
JOB_TM_MEMORY=Job tm memory
JOB_JM_MEMORY=Job jm memory
# JobInfo
BROADCAST_USED_MEMORY=Broadcast used memory
RATIO_MEMORY=Proportion of memory
BASELINE_DURATION=Normal duration interval
BASELINE_END_TIME=Normal end time interval
LAST_SUCCESSFUL_TIME=Last successful time
SINCE_NOW=since now
DAY=day
# CpuWasteService
CPU_WASTE_CONCLUSION_DESC=Calculation Rules：<br/>&nbsp;  \
  Computing resources used by the app = maximum concurrent vCore * app running time<br/> &nbsp;  \
  Computing resources used by job = maximum concurrent vCore * job running time <br/> &nbsp;  \
  Computing resources used by task = cumulative task computing time<br/> &nbsp;  \
  Driver resource waste = computing resources used by app - computing resources used by job <br/> &nbsp;  \
  Executor resource waste = computing resources used by job - computing resources used by task<br/>&nbsp;  \
  When the proportion of executor resource waste exceeds the threshold of %s or the proportion of driver resource waste exceeds the threshold of %s, it is determined that CPU resource waste has occurred
CPU_WASTE_ANALYSIS=CPU Waste Analysis
CPU_WASTE=Waste
CPU_EFFICIENT=Efficient
# MemoryWasteService
MEMORY_WASTE_CONCLUSION_DESC=Memory waste calculation rules::<br/> &nbsp;  \
  Total memory time = executor configuration memory size * number of executors * app running time <br/> &nbsp;  \
  Execution memory consumption time = sum (executor peak memory * executor execution time) <br/>&nbsp;  \
  Percentage of wasted memory = (total memory time - memory time consumed by execution)/total memory time <br/>&nbsp;  \
  When the proportion of memory waste exceeds %s, it is judged that memory waste has occurred
MEMORY_WASTE_ANALYSIS=Memory Waste Analysis
MEMORY_WASTE_CHART_DESC=Peak memory and maximum memory distribution graph of each executor
MEMORY_WASTE_CHART_Y=Memory
MEMORY_WASTE_CHART_FREE=Free Memory
MEMORY_WASTE_CHART_PEAK=Peak Memory
# MRMemoryWasteService
MR_MEMORY_WASTE_CONCLUSION_DESC=Memory waste calculation rules:<br/> &nbsp;  \
  Total memory time = sum(map/reduce configuration memory size * map/reduce running time) <br/> &nbsp;  \
  Execution memory consumption time = sum(map/reduce peak memory * map/reduce execution time) <br/>&nbsp;  \
  Percentage of wasted memory = (total memory time - memory time consumed by execution)/total memory time <br/>&nbsp;  \
  When the proportion of map memory waste exceeds %s or the proportion of reduce memory waste exceeds %s, it is determined that memory waste has occurred
MR_MEMORY_WASTE_CONCLUSION_INFO=%s allocated memory: <span style=\"color: #e24a4a;\">%s</span>, \
  peak memory: <span style=\"color: #e24a4a;\">%s</span>,memory waste: <span style=\"color: #e24a4a;\">%s</span>
MR_MEMORY_WASTE_ANALYSIS=MR Memory Waste Analysis
MR_MEMORY_WASTE_CHART_DESC=%s peak memory and maximum memory distribution graph
# MemoryOverflowService
MEMORY_OVERFLOW_ANALYSIS=Memory Overflow Analysis
MEMORY_OVERFLOW_CONCLUSION=A memory overflow occurred during the running process, please fix the problem according to the key logs and corresponding diagnostic suggestions
MEMORY_OVERFLOW_CONCLUSION_DESC=Capture related logs of memory overflow in Driver/Executor
# OtherExceptionService
OTHER_EXCEPTION_ANALYSIS=Error Log Analysis
OTHER_EXCEPTION_CONCLUSION=An error occurred during the running process, please fix the problem according to the key logs and corresponding diagnostic suggestions
OTHER_EXCEPTION_CONCLUSION_DESC=Capture error logs in Driver/Executor
# RunErrorBaseService
RUN_ERROR_CONCLUSION=No exception detected
# ShuffleFailedService
SHUFFLE_FAILED_ANALYSIS=Shuffle Failed Analysis
SHUFFLE_FAILED_CONCLUSION=Shuffle process failed, please fix the problem according to the key logs and corresponding diagnostic suggestions
SHUFFLE_FAILED_CONCLUSION_DESC=Capture the shuffle error log in Driver/Executor
# SqlFailedService
SQL_FAILED_ANALYSIS=SQL Failed Analysis
SQL_FAILED_CONCLUSION=A syntax error occurred, please fix the problem according to the key logs and corresponding diagnostic suggestions
SQL_FAILED_CONCLUSION_DESC=Capture the syntax error log in Driver/Executor
# RunInfoService
RUN_INFO_CATEGORY_NORMAL=Normal
# BigTableScanService
BIG_TABLE_SCAN_ANALYSIS=Big Table Scan Analysis
BIG_TABLE_SCAN_CONCLUSION_DESC=The task of scanning a table with more than %s rows
# DataSkewService
DATA_SKEW_ANALYSIS=Data Skew Analysis
DATA_SKEW_CONCLUSION_DESC=The data skew diagnosis rules are as follows: <br/> &nbsp;  \
  1. The total task time is >30min<br/> &nbsp;  \
  2. Stage time consumption/total task time consumption>45%%<br/> &nbsp;  \
  3. The data volume of shuffle read meets one of the following conditions：<br> &nbsp;&nbsp;    \
  a. When 50,000 < median value <= 100,000, and maximum value/median value >= 100 <br> &nbsp;&nbsp;    \
  b. When 100,000 < median value < 1 million, and maximum value/median value >= 50 <br/> &nbsp;&nbsp;    \
  c. When 1 million < median value < 5 million, and maximum value/median value >= 10 <br/> &nbsp;&nbsp;    \
  d. When 5 million < median value < 20 million, and maximum value/median value >= 5 <br/> &nbsp;&nbsp;    \
  e. When 20 million < median value < 30 million, and maximum value/median value >= 3.5 <br/> &nbsp;&nbsp;    \
  f. When 30 million < median value < 40 million, and maximum value/median value >= 3 <br/> &nbsp;&nbsp;    \
  g. When 40 million < median value < 50 million, and maximum value/median value >= 2.25 <br/> &nbsp;&nbsp;    \
  h. When 50 million < median value, and maximum value/median value >=2 <br/>
DATA_SKEW_CHART_DESC=Distribution diagram of the ratio between the maximum value and the median value of task Shuffle Read Records in Stage
DATA_SKEW_CHART_MAX=Max Value
DATA_SKEW_CHART_MEDIAN=Median Value
DATA_SKEW_CHART_NORMAL=Normal Value
DATA_SKEW_CHART_STAGE_DESC=Stage[%s]Reduce task Shuffle Read Records
DATA_SKEW_CONCLUSION_INFO=job[<span style="color: #e24a4a;">%s</span>].stage[<span style="color: #e24a4a;">%s</span>].task[<span style="color: #e24a4a;">%s</span>]shuffle read data size: <span style="color: #e24a4a;">%s</span> median: %s
DATA_SKEW_CHART_INFO_NORMAL=Normal Stage
DATA_SKEW_CHART_INFO_ABNORMAL=Abnormal Stage
# GlobalSortService
GLOBAL_SORT_ANALYSIS=Global Sort Analysis
GLOBAL_SORT_CONCLUSION_DESC=Diagnostic rules: <br/>&nbsp;  \
  1. There is a stage in the task that only generates %s task<br/>&nbsp;  \
  2. The amount of data processed exceeds %s rows <br/>&nbsp;  \
  3. The running time exceeds %s minutes<br/>&nbsp;  \
  If all the above conditions are met, it will be determined as a global sorting exception
GLOBAL_SORT_CONCLUSION_INFO=job[<span style=\"color: #e24a4a;\">%d</span>].stage[<span style=\"color: #e24a4a;\">%d</span>]\
  has only one [<span style=\"color: #e24a4a;\">%d</span>]task,data size: <span style=\"color: #e24a4a;\">%s行</span>,\
  duration: <span style=\"color: #e24a4a;\">%s</span>
# HdfsStuckService
HDFS_STUCK_ANALYSIS=HDFS Stuck Analysis
HDFS_STUCK_CONCLUSION_DESC=Calculate the processing rate of each task in the Stage (the ratio of the amount of data read to the time taken). When the ratio of the median to the minimum processing rate is greater than %s, it is determined to be HDFS stuck
HDFS_STUCK_CHART_DESC=Distribution diagram of the ratio of the median and minimum value of task processing data rate in each stage
HDFS_STUCK_CHART_MIN=Min Value
HDFS_STUCK_CHART_MEDIAN=Median Value
HDFS_STUCK_CHART_NORMAL=Normal Value
HDFS_STUCK_CHART_TASK_DESC=Job[%s] Stage[%s] distribution of the ratio between the amount of data read and the time taken for each task(%s)
HDFS_STUCK_CONCLUSION_INFO=job[<span style=\"color: #e24a4a;\">%d</span>].stage[<span style=\"color: #e24a4a;\">%d</span>].task[<span style=\"color: #e24a4a;\">%d</span>]\
  processing rate: <span style=\"color: #e24a4a;\">%.2f</span>MB/s median: %.2fMB/s
HDFS_STUCK_CHART_STAGE_NORMAL=Normal Stage
HDFS_STUCK_CHART_STAGE_ABNORMAL=Abnormal Stage
# JobDurationService
JOB_DURATION_ABNORMAL_ANALYSIS=Job Duration Abnormal Analysis
JOB_DURATION_CONCLUSION_DESC=If the ratio of the idle time in the job (total job time - accumulated stage time) to the total time exceeds %s%%, the job is judged to be abnormal duration
JOB_DURATION_CHART_DESC=Calculation per job - idle time distribution(%s)
JOB_DURATION_CHART_COMPUTE=Job calculation time
JOB_DURATION_CHART_IDLE=Job  idle time
# MRBigTableScanService
MR_BIG_TABLE_SCAN_ANALYSIS=MR Big Table Scan Analysis
MR_BIG_TABLE_SCAN_CONCLUSION_DESC=The task of scanning a table with more than %s rows
# MRDataSkewService
MR_DATA_SKEW_ANALYSIS=MR Data Skew Analysis
MR_DATA_SKEW_CONCLUSION_DESC=The maximum amount of data processed by the task exceeds %sMB, the time exceeds %sms, the maximum/median ratio map exceeds %s or the reduce exceeds %s
MR_DATA_SKEW_CHART_Y=Data Size
MR_DATA_SKEW_CHART_MAX=Max Value
MR_DATA_SKEW_CHART_MEDIAN=Median Value
MR_DATA_SKEW_CHART_NORMAL=Normal Value
MR_DATA_SKEW_CHART_TASK_DESC=%s task processing data size distribution chart
MR_DATA_SKEW_CONCLUSION_INFO=%s task[<span style=\"color: #e24a4a;\">%s</span>]\
  data size: <span style=\"color: #e24a4a;\">%s</span>\
  duration: <span style=\"color: #e24a4a;\">%s</span>, median: %s
# MRGCService
MR_GC_ANALYSIS=MR GC Abnormal Analysis
MR_GC_CONCLUSION_DESC=Task GC average time/CPU average time ratio map exceeds %s or reduce exceeds %s
MR_GC_CONCLUSION_INFO=%s average GC time: <span style=\"color: #e24a4a;\">%s ms</span>, \
  average CPU time: <span style=\"color: #e24a4a;\">%s ms</span>, \
  GC time/CPU time: <span style=\"color: #e24a4a;\">%s</span>, \
  exceeding the threshold: <span style=\"color: #e24a4a;\">%s</span>
MR_GC_CHART_DESC=%s GC time and CPU time distribution chart
MR_GC_CHART_Y=duration
MR_GC_CHART_GC_TIME=GC Time
MR_GC_CHART_CPU_TIME=CPU Time
# MRSpeculativeTaskService
MR_SPECULATIVE_ANALYSIS=MR Speculative Analysis
MR_SPECULATIVE_CONCLUSION_DESC=There are more than %s speculative execution tasks in mapreduce
MR_SPECULATIVE_CHART_DESC=Speculative task duration
MR_SPECULATIVE_DURATION=Duration
# MRTaskLongTailService
MR_LONG_TAIL_ANALYSIS=MR Long Tail Analysis
MR_LONG_TAIL_CONCLUSION_DESC=The maximum value of task running time exceeds %sms, the maximum/median ratio map exceeds %s or the reduce exceeds %s
MR_LONG_TAIL_CHART_DESC=%s task duration
MR_LONG_TAIL_CONCLUSION_INFO=%s task[<span style="color: #e24a4a;">%s</span>]\
  duration: <span style="color: #e24a4a;">%s</span> median: %s
MR_LONG_TAIL_CHART_Y=duration
MR_LONG_TAIL_CHART_MAX=Max Value
MR_LONG_TAIL_CHART_MEDIAN=Median Value
MR_LONG_TAIL_CHART_NORMAL=Normal Value
# OOMWarnService
OOM_WARN_ANALYSIS=OOM Warn Analysis
OOM_WARN_CONCLUSION_DESC=If the cumulative memory of the broadcast table accounts for more than 40% of the memory of the driver or executor, it is determined to be an OOM warning
# SpeculativeTaskService
SPECULATIVE_TASK_ANALYSIS=Speculative Task Analysis
SPECULATIVE_TASK_CONCLUSION_DESC=If the number of speculative execution tasks in a stage exceeds %s, it can be determined as excessive speculative execution.
SPECULATIVE_TASK_CHART_DESC=Number of speculative executions per stage
SPECULATIVE_TASK_CHART_Y=Amount
SPECULATIVE_TASK_CHART_NORMAL=Normal Stage
SPECULATIVE_TASK_CHART_ABNORMAL=Abnormal stage
# StageDurationService
STAGE_DURATION_ANALYSIS=Stage Duration Abnormal Analysis
STAGE_DURATION_CONCLUSION_DESC=If the ratio of Stage idle time (stage running time - task running time) to stage duration exceeds %s%%, it is determined that the Stage duration is abnormal.
STAGE_DURATION_CHART_DESC=Each stage compute-idle time distribution(%s)
STAGE_DURATION_CHART_COMPUTE=Stage compute time
STAGE_DURATION_CHART_IDLE=Stage idle time
# TaskLongTailService
TASK_LONG_TAIL_ANALYSIS=Task Long Tail Analysis
TASK_LONG_TAIL_CONCLUSION_DESC=If the ratio of the maximum task duration to the median value in a Task is greater than %s, it is determined that the task long tail.
TASK_LONG_TAIL_CONCLUSION_INFO=job[<span style=\"color: #e24a4a;\">%d</span>].stage[<span style=\"color: #e24a4a;\">%d</span>]\
  .task[<span style=\"color: #e24a4a;\">%d</span>]duration: <span style=\"color: #e24a4a;\">%s</span> median: %s
TASK_LONG_TAIL_CHART_STAGE_DESC=Distribution chart of the maximum and median duration of each stage task
TASK_LONG_TAIL_CHART_TASK_DESC=Stage[%s]each task duration(%s)
TASK_LONG_TAIL_CHART_MAX=Max Value
TASK_LONG_TAIL_CHART_MEDIAN=Median Value
TASK_LONG_TAIL_CHART_NORMAL=Normal Value
TASK_LONG_TAIL_CHART_STAGE_NORMAL=Normal Stage
TASK_LONG_TAIL_CHART_STAGE_ABNORMAL=Abnormal Stage
# ReportServiceImpl
CPU_USAGE_TREND=CPU Usage
CPU_DIAGNOSIS_TREND=Abnormal CPU
CPU_TOTAL_TREND=Total CPU
MEMORY_USAGE_TREND=Memory Usage
MEMORY_DIAGNOSIS_TREND=Abnormal Memory
MEMORY_TOTAL_TREND=Total Memory
AMOUNT_TREND=Amount Trend
DIAGNOSIS_JOB=Abnormal Jobs
TOTAL_JOB=Total Jobs
CPU_RESOURCE_USAGE_DISTRIBUTION=CPU Usage
MEMORY_RESOURCE_USAGE_DISTRIBUTION=Memory Usage
JOB_AMOUNT_DISTRIBUTION=Abnormal Jobs
# FlinkTaskDiagnosisServiceImpl
CPU_OPTIMIZE=Optimizable CPU
CPU_TOTAL_USAGE=Total CPU
MEMORY_OPTIMIZE=Optimizable Memory
MEMORY_TOTAL_USAGE=Total Memory
JOB_AMOUNT_TREND=Jobs
JOB_AMOUNT_UNIT=Piece
JOB_AMOUNT_EXCEPTION=Abnormal Jobs
# JobServiceImpl
TRY_NUMBER=The %dth try times
APPLICATION_NOT_EXIST=applicationId does not exist
APPLICATION_CATEGORY=This application occurs 
APPLICATION_EXCEPTION=%s. Please click to view the diagnostic report for details.
ABNORMAL_LOG_ANALYSIS=Abnormal Log Analysis
ABNORMAL_LOG_CONCLUSION=An error occurred during the running process. Please correct the problem according to the key logs and corresponding diagnostic suggestions.
ABNORMAL_LOG_CONCLUSION_DESC=Capture the error log in the scheduler
ABNORMAL_LOG_SUMMARY=%dth try times error log summary
JOB_DURATION_ANALYSIS=Run Time-consuming Analysis
JOB_DURATION_TREND=Duration Trend
JOB_EXECUTION_DATE=Execution Date
JOB_DURATION=Duration
MAX_VALUE=Max value
BASELINE_TIME_ANALYSIS=Baseline time anomaly analysis
BASELINE_TIME_CONCLUSION=The end time of this task is %s, the baseline time is %s, and it runs late
BASELINE_TIME_CONCLUSION_DESC=Based on the upstream and downstream relationships of the task, analyze the reasons for the delay of this task
JOB_DURATION_INFO=The duration of this task is %s
BASELINE_DURATION_INFO=%s, the baseline duration is %s
DURATION_EXCEPTION=%s, abnormal duration
DURATION_NORMAL=%s, normal duration
OTHER_ERROR=Other Error
YARN_ERROR=The '%s' exception was detected in the Yarn log. For detailed logs and diagnostic suggestions, please see exception log analysis.
SCHEDULER_ERROR=The '%s' exception was detected from the scheduling log. For detailed logs and diagnostic suggestions, please see exception log analysis.
OCCUR=%s occur %s
# OneClickDiagnosisServiceImpl
UNSUPPORTED_TYPE=%s are not supported yet
APP_DIAGNOSIS_DONE=The applicationId has been diagnosed
APP_DIAGNOSIS_PROCESSING=%s is diagnosing, total number of files: %d, number of parsed files: %d
APP_DIAGNOSIS_SUCCEED=%s diagnosis successful
APP_DIAGNOSIS_FAILED=%s diagnosis failed, please contact the system administrator
APP_DIAGNOSIS_SENDING=sending diagnosis, please wait
