server:
  port: 7001

spring:
  application:
    name: task-flink
  mvc:
    pathmatch:
      matching-strategy: ANT_PATH_MATCHER
  profiles:
    active:
    jackson:
      time-zone: GMT+8
      date-format: yyyy-MM-dd HH:mm:ss
  datasource:
    url: jdbc:mysql://localhost:33066/diagnose_data?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai
    username:
    password:
    druid:
      initial-size: 5 # Connection pool initialization size
      min-idle: 10 # Minimum number of idle connections
      max-active: 20 # Maximum number of connections
  kafka:
    bootstrap-servers: "localhost:9095"
    taskApplicationTopic: "task-application"
    flinkTaskApp: "flink-task-app"
    consumer:
      group-id: "task-flink-diagnosis-local"
      auto-offset-reset: "latest"  # Start consuming from the submitted offset. If no offset is submitted, consume from the beginning.
      max-poll-interval-ms: 300000  # The time interval between two active consumptions is 5 minutes
  opensearch:
    hosts: localhost:19527
    username:
    password:
    truststore:
    truststore-password:

mybatis:
  mapper-locations:
    - classpath:dao/*.xml
    - classpath*:com/**/mapper/*.xml
  configuration: # print sql
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl

diagnosis:
  flinkPrometheusHost: http://localhost:9090
  flinkPrometheusToken:
  flinkPrometheusDatabase:

custom:
  opensearch:
    yarnIndex:
      name: "compass-yarn-app"
    flinkReportIndex:
      name: "compass-flink-report"
    flinkTaskAnalysisIndex:
      name: "compass-flink-task-analysis"
